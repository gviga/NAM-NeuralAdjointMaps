{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example notebook on how to use NAM library for shape matching\n",
    "In this notebook we consider different refinement with the spectral embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from model.neural_adjoint_map import *\n",
    "from model.optimizer import *\n",
    "from methods.linear_ref import *\n",
    "from methods.nam_ref import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('./../../NRP/Unsupervised-Learning-of-Robust-Spectral-Shape-Matching/')\n",
    "import logging\n",
    "from os import path as osp\n",
    "\n",
    "from datasets import build_dataset\n",
    "from models import build_model\n",
    "\n",
    "import yaml\n",
    "from utils.tensor_util import to_device,to_numpy\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#torch.cuda.set_device(0)\n",
    "\n",
    "#pointcloud\n",
    "\n",
    "DATASET='dt4d_interclass'\n",
    "\n",
    "with open('./../../NRP/Unsupervised-Learning-of-Robust-Spectral-Shape-Matching/options/test/'+DATASET+'.yaml', 'r') as f:\n",
    "    opt = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "opt['is_train']=False\n",
    "test_set = build_dataset(opt['datasets']['test_dataset'])\n",
    "\n",
    "shape1=test_set[3]['first']\n",
    "shape2=test_set[3]['second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "fsf: 0.037019912339746955\n",
      "zo: 0.03625019071623683\n",
      "ima: 0.07355247605592012\n",
      "abzo: 0.036790350824594496\n",
      "n_fsf: 0.05690628681331873\n",
      "n_zo: 0.03595277238637209\n",
      "n_ima: 0.058093071170151236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load configuration\n",
    "DATASET='shrec19'\n",
    "with open('./../../NRP/Unsupervised-Learning-of-Robust-Spectral-Shape-Matching/options/test/'+DATASET+'.yaml', 'r') as f:\n",
    "    opt = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "test_set = build_dataset(opt['datasets']['test_dataset'])\n",
    "opt['is_train'] = False\n",
    "model = build_model(opt)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize variables\n",
    "n_exp = 50\n",
    "n_k = len(range(20, 201, 20)) + 1\n",
    "mse_nzo = np.zeros((n_exp, n_k))\n",
    "g_nzo = np.zeros((n_exp, n_k))\n",
    "\n",
    "#ind=np.random.randint(0,len(test_set),n_exp)\n",
    "ind=np.arange(n_exp)\n",
    "\n",
    "results = {}\n",
    "\n",
    "zo = []\n",
    "abzo =[]\n",
    "ima_l = []\n",
    "fsf_l = []\n",
    "\n",
    "n_zo = []\n",
    "n_ima = []\n",
    "n_fsf = []\n",
    "\n",
    "import h5py\n",
    "\n",
    "for i in ind:\n",
    "    data_x, data_y = to_device(test_set[i]['second'], device), to_device(test_set[i]['first'], device)\n",
    "    if data_x['name'] != data_y['name']:\n",
    "        dist_y = data_y['dist'].cpu()\n",
    "        corr_x = data_x['corr']\n",
    "        corr_y = data_y['corr']\n",
    "        dist_y = to_numpy(dist_y)\n",
    "        corr_x = to_numpy(corr_x)\n",
    "        corr_y = to_numpy(corr_y)\n",
    "        #C = torch.linalg.pinv(data_y['evecs'][corr_y, :20]) @ data_x['evecs'][corr_x, :20]\n",
    "        #p2p_ini = nearest(data_x['evecs'][:, :20], data_y['evecs'][:, :20] @ C).cpu().numpy()\n",
    "        with h5py.File('/home/ubuntu/NRP//NRP/nfr/results/mesh/'+DATASET+'/results.h5', 'r+') as hf:\n",
    "            p2p_ini=hf[f'unsup_noref_{i}'][:]\n",
    "\n",
    "        p2p=fsf(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        fsf_l.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=zoomout(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        zo.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=ima(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        ima_l.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=ab_zoomout(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        abzo.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=neural_ima(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        n_ima.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=neural_zoomout(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        n_zo.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "        p2p=neural_fsf(data_x['evecs'],data_y['evecs'],p2p_ini,20,201,20).cpu()\n",
    "        n_fsf.append(model.metrics['geo_error'](dist_y, corr_y, corr_x, p2p, return_mean=False).mean().item())\n",
    "\n",
    "    i=i+1\n",
    "    print(i)\n",
    "print('fsf:',np.mean(fsf_l))\n",
    "print('zo:',np.mean(zo))\n",
    "print('ima:',np.mean(ima_l))\n",
    "print('abzo:',np.mean(abzo))\n",
    "\n",
    "print('n_fsf:',np.mean(n_fsf))\n",
    "print('n_zo:',np.mean(n_zo))\n",
    "print('n_ima:',np.mean(n_ima))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsf: 0.037019912339746955\n",
      "zo: 0.03625019071623683\n",
      "ima: 0.07355247605592012\n",
      "abzo: 0.036790350824594496\n",
      "n_fsf: 0.05690628681331873\n",
      "n_zo: 0.03595277238637209\n",
      "n_ima: 0.058093071170151236\n"
     ]
    }
   ],
   "source": [
    "print('fsf:',np.mean(fsf_l[:len(n_fsf)]))\n",
    "print('zo:',np.mean(zo[:len(n_fsf)]))\n",
    "print('ima:',np.mean(ima_l[:len(n_fsf)]))\n",
    "print('abzo:',np.mean(abzo[:len(n_fsf)]))\n",
    "\n",
    "print('n_fsf:',np.mean(n_fsf[:len(n_fsf)]))\n",
    "print('n_zo:',np.mean(n_zo[:len(n_fsf)]))\n",
    "print('n_ima:',np.mean(n_ima[:len(n_fsf)]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
